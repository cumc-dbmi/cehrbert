model_name_or_path: "test_results"
tokenizer_name_or_path: "test_results"

data_folder: "sample_data/pretrain"
dataset_prepared_path: "test_dataset_prepared"
validation_split_percentage: 0.05
validation_split_num: 1000
preprocessing_num_workers: 4
preprocessing_batch_size: 1000
streaming: True

#Tokenizer
vocab_size: 50000
min_frequency: 0

# Below is a list of Med-to-CehrBert related arguments
att_function_type: "cehrbert"
is_data_in_meds: false
inpatient_att_function_type: "none"
include_auxiliary_token: true
include_demographic_prompt: false

do_train: true
overwrite_output_dir: false
resume_from_checkpoint: # path to the checkpoint folder
seed: 42

num_hidden_layers: 6
max_position_embeddings: 512

# torch dataloader configs
dataloader_num_workers: 4
dataloader_prefetch_factor: 4

output_dir: "test_results"
evaluation_strategy: "epoch"
save_strategy: "epoch"
learning_rate: 0.00005
per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 1
num_train_epochs: 2
# When streaming is set to True, max_steps needs to be provided
max_steps: 100

warmup_steps: 500
weight_decay: 0.01
logging_dir: "./logs"
logging_steps: 100
save_total_limit:
load_best_model_at_end: true
metric_for_best_model: "eval_loss"
greater_is_better: false
